<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

  <property>
    <name>dfs.block.access.token.enable</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.block.local-path-access.user</name>
    <value>work, hbase, hbase_srv, hbase_tst, hbase_prc, impala, sql_prc</value>
  </property>

  <property>
    <name>dfs.block.replicator.classname</name>
    <value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
  </property>

  <property>
    <name>dfs.block.size</name>
    <value>128m</value>
  </property>

  <property>
    <name>dfs.blockreport.initialDelay</name>
    <value>600</value>
  </property>

  <property>
    <name>dfs.blocksize</name>
    <value>256m</value>
  </property>

  <property>
    <name>dfs.client.failover.proxy.provider.c3prc-hadoop</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ZkConfiguredFailoverProxyProvider</value>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit.skip.auth</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.client.slow.log.threshold.ms</name>
    <value>10000</value>
  </property>

  <property>
    <name>dfs.cluster.administrators</name>
    <value>hdfs_admin</value>
  </property>

  <property>
    <name>dfs.datanode.address</name>
    <value>0.0.0.0:11402</value>
  </property>

  <property>
    <name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold</name>
    <value>107374182400</value>
  </property>

  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>20971520</value>
  </property>

  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/home/work/hdd1/hdfs/c3prc-hadoop/datanode,/home/work/hdd2/hdfs/c3prc-hadoop/datanode,/home/work/hdd3/hdfs/c3prc-hadoop/datanode,/home/work/hdd4/hdfs/c3prc-hadoop/datanode,/home/work/hdd5/hdfs/c3prc-hadoop/datanode,/home/work/hdd6/hdfs/c3prc-hadoop/datanode,/home/work/hdd7/hdfs/c3prc-hadoop/datanode,/home/work/hdd8/hdfs/c3prc-hadoop/datanode,/home/work/hdd9/hdfs/c3prc-hadoop/datanode,/home/work/hdd10/hdfs/c3prc-hadoop/datanode,/home/work/hdd11/hdfs/c3prc-hadoop/datanode,/home/work/hdd12/hdfs/c3prc-hadoop/datanode</value>
  </property>

  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>700</value>
  </property>

  <property>
    <name>dfs.datanode.du.reserved</name>
    <value>53687091200</value>
  </property>

  <property>
    <name>dfs.datanode.enable.raid.service</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>2</value>
  </property>

  <property>
    <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
    <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy</value>
  </property>

  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:11401</value>
  </property>

  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>0.0.0.0:11400</value>
  </property>

  <property>
    <name>dfs.datanode.kerberos.principal</name>
    <value>hdfs_prc/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.datanode.keytab.file</name>
    <value>/etc/hadoop/conf/hdfs_prc.keytab</value>
  </property>

  <property>
    <name>dfs.datanode.max.xcievers</name>
    <value>4096</value>
  </property>

  <property>
    <name>dfs.datanode.overused.freespace.threshold</name>
    <value>107374182400</value>
  </property>

  <property>
    <name>dfs.datanode.overused.percentage.threshold</name>
    <value>90</value>
  </property>

  <property>
    <name>dfs.datanode.reserved.space.block.number</name>
    <value>200</value>
  </property>

  <property>
    <name>dfs.datanode.scan.period.hours</name>
    <value>-1</value>
  </property>

  <property>
    <name>dfs.datanode.sync.behind.writes</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.datanode.synconclose</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.domain.socket.path</name>
    <value>/home/work/app/hdfs/c3prc-hadoop/datanode/dn_socket</value>
  </property>

  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence&#xA;shell(/bin/true)</value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.connect-timeout</name>
    <value>2000</value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/work/.ssh/id_rsa</value>
  </property>

  <property>
    <name>dfs.ha.namenodes.c3prc-hadoop</name>
    <value>host0,host1</value>
  </property>

  <property>
    <name>dfs.ha.tail-edits.period</name>
    <value>20</value>
  </property>

  <property>
    <name>dfs.ha.zkfc.port</name>
    <value>11300</value>
  </property>

  <property>
    <name>dfs.hosts.exclude</name>
    <value>/home/work/app/hdfs/c3prc-hadoop/namenode/excludes</value>
  </property>

  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/home/work/hdd/hdfs/c3prc-hadoop/journalnode</value>
  </property>

  <property>
    <name>dfs.journalnode.http-address</name>
    <value>0.0.0.0:11101</value>
  </property>

  <property>
    <name>dfs.journalnode.kerberos.internal.spnego.principal</name>
    <value>HTTP/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.journalnode.kerberos.principal</name>
    <value>hdfs_prc/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.journalnode.keytab.file</name>
    <value>/etc/hadoop/conf/hdfs_prc.keytab</value>
  </property>

  <property>
    <name>dfs.journalnode.rpc-address</name>
    <value>0.0.0.0:11100</value>
  </property>

  <property>
    <name>dfs.metrics.percentiles.intervals</name>
    <value>60,300,900</value>
  </property>

  <property>
    <name>dfs.namenode.acls.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.namenode.avoid.read.stale.datanode</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.namenode.avoid.write.stale.datanode</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.namenode.check.stale.datanode</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.namenode.checkpoint.txns</name>
    <value>2000000</value>
  </property>

  <property>
    <name>dfs.namenode.delegation.token.max-lifetime</name>
    <value>31536000000</value>
  </property>

  <property>
    <name>dfs.namenode.fs-limits.max-directory-items</name>
    <value>2097152</value>
  </property>

  <property>
    <name>dfs.namenode.handler.count</name>
    <value>128</value>
  </property>

  <property>
    <name>dfs.namenode.http-address.c3prc-hadoop.host0</name>
    <value>c3-hadoop-prc-ct04.bj:11201</value>
  </property>

  <property>
    <name>dfs.namenode.http-address.c3prc-hadoop.host1</name>
    <value>c3-hadoop-prc-ct05.bj:11201</value>
  </property>

  <property>
    <name>dfs.namenode.kerberos.internal.spnego.principal</name>
    <value>HTTP/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.namenode.kerberos.principal</name>
    <value>hdfs_prc/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.namenode.keytab.file</name>
    <value>/etc/hadoop/conf/hdfs_prc.keytab</value>
  </property>

  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/home/work/hdd/hdfs/c3prc-hadoop/namenode</value>
  </property>

  <property>
    <name>dfs.namenode.replica.delete.randomly</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.namenode.replication.min</name>
    <value>1</value>
  </property>

  <property>
    <name>dfs.namenode.rpc-address.c3prc-hadoop.host0</name>
    <value>c3-hadoop-prc-ct04.bj:11200</value>
  </property>

  <property>
    <name>dfs.namenode.rpc-address.c3prc-hadoop.host1</name>
    <value>c3-hadoop-prc-ct05.bj:11200</value>
  </property>

  <property>
    <name>dfs.namenode.safemode.threshold-pct</name>
    <value>0.99f</value>
  </property>

  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>32</value>
  </property>

  <property>
    <name>dfs.namenode.servicerpc-address.c3prc-hadoop.host0</name>
    <value>c3-hadoop-prc-ct04.bj:11202</value>
  </property>

  <property>
    <name>dfs.namenode.servicerpc-address.c3prc-hadoop.host1</name>
    <value>c3-hadoop-prc-ct05.bj:11202</value>
  </property>

  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://c3-hadoop-prc-ct01.bj:11100;c3-hadoop-prc-ct02.bj:11100;c3-hadoop-prc-ct03.bj:11100;c3-hadoop-prc-ct04.bj:11100;c3-hadoop-prc-ct05.bj:11100/c3prc-hadoop</value>
  </property>

  <property>
    <name>dfs.namenode.stale.datanode.interval</name>
    <value>30000</value>
  </property>

  <property>
    <name>dfs.namenode.upgrade.permission</name>
    <value>0777</value>
  </property>

  <property>
    <name>dfs.nameservices</name>
    <value>c3prc-hadoop</value>
  </property>

  <property>
    <name>dfs.permissions</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.permissions.superuser</name>
    <value>hdfs_admin</value>
  </property>

  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>supergroup</value>
  </property>

  <property>
    <name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name>
    <value>HTTP/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.secondary.namenode.kerberos.principal</name>
    <value>hdfs_prc/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.secondary.namenode.keytab.file</name>
    <value>/etc/hadoop/conf/hdfs_prc.keytab</value>
  </property>

  <property>
    <name>dfs.ttlmanager.kerberos.internal.spnego.principal</name>
    <value>HTTP/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.ttlmanager.kerberos.principal</name>
    <value>hdfs_prc/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.ttlmanager.keytab.file</name>
    <value>/etc/hadoop/conf/hdfs_prc.keytab</value>
  </property>

  <property>
    <name>dfs.web.authentication.kerberos.keytab</name>
    <value>/etc/hadoop/conf/hdfs_prc.keytab</value>
  </property>

  <property>
    <name>dfs.web.authentication.kerberos.principal</name>
    <value>HTTP/hadoop@XIAOMI.HADOOP</value>
  </property>

  <property>
    <name>dfs.web.ugi</name>
    <value>hdfs,supergroup</value>
  </property>

  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>fs.permissions.umask-mode</name>
    <value>022</value>
  </property>

  <property>
    <name>fs.trash.checkpoint.interval</name>
    <value>1440</value>
  </property>

  <property>
    <name>fs.trash.interval</name>
    <value>10080</value>
  </property>

  <property>
    <name>hadoop.proxyuser.impala.groups</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.impala.hosts</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.sql_prc.groups</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.sql_prc.hosts</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.security.group.mapping</name>
    <value>org.apache.hadoop.security.ConfigurationBasedGroupsMapping</value>
  </property>

  <property>
    <name>hadoop.security.group.mapping.file.name</name>
    <value>/home/work/app/hdfs/c3prc-hadoop/namenode/hadoop-groups.conf</value>
  </property>

  <property>
    <name>ignore.secure.ports.for.testing</name>
    <value>true</value>
  </property>

  <property>
    <name>net.topology.node.switch.mapping.impl</name>
    <value>org.apache.hadoop.net.TableMapping</value>
  </property>

  <property>
    <name>net.topology.table.file.name</name>
    <value>/home/work/app/hdfs/c3prc-hadoop/namenode/rackinfo.txt</value>
  </property>

</configuration>
